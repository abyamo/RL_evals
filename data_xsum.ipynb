{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b41a94d",
   "metadata": {},
   "source": [
    "# Get data set for semantic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da0fb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"EdinburghNLP/xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10436b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"test\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee965989",
   "metadata": {},
   "source": [
    "# Calculate Similarity Metrics\n",
    "\n",
    "As per this paper: https://arxiv.org/html/2402.17008v1#S4\n",
    "\n",
    "\"ROUGE: ROUGE Lin (2004) is a family of metrics that score the lexical overlap between the generated text and the reference text. We used 3 variations, R-1, R-2, and R-L, which are widely adopted for evaluating text summarizing tasks. However, despite its popularity, works like Akter et al. (2022) and Bansal et al. (2022b) show that ROUGE is an unsuitable metric for comparing semantics. For this reason we also evaluate using metrics that have been designed with semantic awareness in mind.\n",
    "\n",
    "BERTscore: While ROUGE can only convey information about lexical overlap, BERTscore is a metric that utilizes contextual embeddings from transformer models like BERT to evaluate the semantic similarity between the generated text and reference text. For this study, we compute BERTscore with the hashcode roberta-large_ L17_ no-idf_ version=0.3.12(hug_ trans=4.36.2)-rescaled.\n",
    "\n",
    "SEM-F1: While ROUGE and BERTscore are useful and powerful metrics, SEM-F1 was specifically designed for the SOS task. SEM-F1 leverages rigorously fine-tuned sentence encoders to evaluate the SOS task using sentence-level similarity. It differs from BERTscore as BERTscore computes token-level similarity. For this study, we compute SEM-F1 with underlying models: USE Cer et al. (2018), RoBERTa Zhuang et al. (2021), and DistilRoBERTa Sanh et al. (2019).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4963531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "from rouge_score import rouge_scorer \n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaa4af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "scores = scorer.score(ds[\"test\"][0][\"document\"], ds[\"test\"][0][\"summary\"])\n",
    "print(scores['rouge1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14d2edee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is a \"chronic\" need for more housing for prison leavers in Wales, according to a charity.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"test\"][0][\"summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10d5f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "P, R, F1 = score(ds[\"test\"][0][\"summary\"], ds[\"test\"][0][\"summary\"], lang=\"en\")\n",
    "print(F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d49981",
   "metadata": {},
   "source": [
    "# Prompt Generation \n",
    "Generate Prompt following: TELeR Prompts\n",
    "\n",
    "Task: Summarize the following newsletter article in exactly one sentence that captures its core message.\n",
    "\n",
    "Explanation: You are summarizing for industry professionals who need a fast, high-level understanding of the article. Your summary should include the key topic, any notable findings or updates, and the article’s main implication or takeaway.\n",
    "\n",
    "Limitations:\n",
    "\n",
    "Do not exceed one sentence.\n",
    "Do not use bullet points or lists.\n",
    "Do not add commentary, opinion, or context not present in the original article.\n",
    "Use clear, informative language appropriate for a professional audience.\n",
    "\n",
    "Input Article:\n",
    "[Insert Any of test set articels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4586b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ds[\"test\"]\n",
    "to_test=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ca7e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, min(to_test, len(test_set))):\n",
    "    article_text = test_set[i][\"document\"]\n",
    "    prompt_template = (\n",
    "        \"Task: Summarize the following newsletter article in exactly one sentence that captures its core message.\\n\\n\"\n",
    "        \"Explanation: You are summarizing for industry professionals who need a fast, high-level understanding of the article. \"\n",
    "        \"Your summary should include the key topic, any notable findings or updates, and the article’s main implication or takeaway.\\n\\n\"\n",
    "        \"Limitations:\\n\\n\"\n",
    "        \"Do not exceed one sentence.\\n\"\n",
    "        \"Do not use bullet points or lists.\\n\"\n",
    "        \"Do not add commentary, opinion, or context not present in the original article.\\n\"\n",
    "        \"Use clear, informative language appropriate for a professional audience.\\n\\n\"\n",
    "        \"Input Article:\\n\"\n",
    "        f\"{article_text}\"\n",
    "    )\n",
    "    data = {\"text\": prompt_template}\n",
    "    with open(f\"prompt_{i}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a50b01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "04_MIT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
